{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, label=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.label = label\n",
    "\n",
    "class CharacterDecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # caso base 1: atingimos o limite de profundidade\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return Node(value=np.max(Counter(y)))\n",
    "\n",
    "        # caso base 2: todas as amostras pertencem a mesma classe\n",
    "        if len(set(y)) == 1:\n",
    "            return Node(value=y[0])\n",
    "\n",
    "        # caso base 3: não há mais características para dividir\n",
    "        if n_features == 0:\n",
    "            return Node(value=np.max(Counter(y)))\n",
    "\n",
    "        # seleciona a melhor característica e limiar para dividir os dados\n",
    "        best_feature, best_threshold = self._choose_split_feature(X, y)\n",
    "\n",
    "        # divide os dados baseado na característica e limiar selecionados\n",
    "        left_idx, right_idx = self._split_data(X[:, best_feature], best_threshold)\n",
    "        X_left, y_left = X[left_idx], y[left_idx]\n",
    "        X_right, y_right = X[right_idx], y[right_idx]\n",
    "\n",
    "        # constrói a subárvore recursivamente\n",
    "        left_subtree = self._build_tree(X_left, y_left, depth + 1)\n",
    "        right_subtree = self._build_tree(X_right, y_right, depth + 1)\n",
    "\n",
    "        # retorna a raiz da subárvore construída\n",
    "        return Node(best_feature, best_threshold, left_subtree, right_subtree)\n",
    "\n",
    "    def _choose_split_feature(self, X, y):\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_entropy = float('inf')\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            values = X[:, feature]\n",
    "            for threshold in set(values):\n",
    "                left_idx, right_idx = self._split_data(values, threshold)\n",
    "\n",
    "                left_entropy = self._calculate_entropy(y[left_idx])\n",
    "                right_entropy = self._calculate_entropy(y[right_idx])\n",
    "\n",
    "                total_entropy = (len(left_idx) / len(y)) * left_entropy + (len(right_idx) / len(y)) * right_entropy\n",
    "\n",
    "                if total_entropy < best_entropy:\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "                    best_entropy = total_entropy\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _split_data(self, values, threshold):\n",
    "        left_idx = np.where(values <= threshold)[0]\n",
    "        right_idx = np.where(values > threshold)[0]\n",
    "        return left_idx, right_idx\n",
    "\n",
    "    def _calculate_entropy(self, labels):\n",
    "        n_labels = len(labels)\n",
    "        if n_labels <= 1:\n",
    "            return 0\n",
    "\n",
    "        counts = np.bincount(labels)\n",
    "        probs = counts / n_labels\n",
    "        probs = probs[np.nonzero(probs)]\n",
    "        return -np.sum(probs * np.log2(probs))\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf():\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(x, node.right)\n",
    "\n",
    "import json\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados do arquivo JSON\n",
    "with open('characters.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Separar características e rótulos\n",
    "X = [[character['height'], character['weight'], character['age'], character['gender'] == 'male'] for character in data['characters']]\n",
    "y = [character['name'] for character in data['characters']]\n",
    "\n",
    "# Dividir os dados em conjunto de treinamento e teste\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "# X_test = np.array(X_test)\n",
    "# y_test = np.array(y_test)\n",
    "# X_train = X_train.astype(np.float)\n",
    "# X_test = X_test.astype(np.float)\n",
    "# y_train = y_train.astype(np.float)\n",
    "# y_test = y_test.astype(np.float)\n",
    "\n",
    "# Treinar a árvore de decisão\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Testar a precisão da árvore\n",
    "y_pred = clf.predict(X)\n",
    "print(accuracy_score(y, y_pred))\n",
    "\n",
    "# tree.plot_tree(clf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
